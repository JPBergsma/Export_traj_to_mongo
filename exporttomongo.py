import re
import datetime
import warnings
from typing import List, Union
import numpy as np
import MDAnalysis as mda
import pymatgen.core
from pathlib import Path
from io import StringIO
import math

#sys.path.append("/home/kwibus/PycharmProjects/Optimade/optimade-python-tools/")
from optimade.server.config import CONFIG
from optimade.server.entry_collections import create_collection
from optimade.models.trajectories import TrajectoryResource
from optimade.models.references import ReferenceResource
from optimade.models.utils import ANONYMOUS_ELEMENTS
from optimade.server.mappers import TrajectoryMapper, ReferenceMapper


def load_trajectory_data(
        structure_file: Union[str, Path, StringIO],
        trajectory_files: List[Union[Path, str]] = None,
        references: List[dict] = None,
        first_frame: int = 0,
        last_frame: int = None,
        frame_step: int = 1,
        traj_id: str = None,
        reference_frames: Union[List[int], int] = None,
        file_format: str = None,
        custom_fields: dict = {}
    ):
    """This function loads a trajectory file with MDAnalysis library and Extracts the OPTIMADE fields and stores it in mongoDB.

    arguments: structure_file: A file containing the structural information about the compounds in the trajectory.
                               If there is no separate trajectory file it can also contain trajectory information.
                               It is also possible to add a stringIO object. In that case the file type should be specified with file_format.
               trajectory_files: a list of files containing the trajectory.
               references: A list of dictionaries containing references belonging to this trajectory.
                           Valid fields are all the fields defined by the BibTeX standard.
                           Each reference should have an id field(string) that is unique within the database.
               (warning: The slicing parameters first_frame, frame_step and last_frame have not tested this slicing properly yet.)
               first_frame: In case only a part of the trajectory should be used this indicates the first frame that should be stored in the data base.
               frame_step: Only 1 out of every frame_step frames will be stored on the server.
               last_frame: The last frame which should be stored in the database.
               traj_id : An id for this trajectory that is unique within the database. If no id is provided the id from mongo DB will be used.
               reference_frame: This indicates which frame will be used to generate the reference structure.
               file_format: the filetype of the input stream as defined by the MDAnalysis package. example "PDB"
               custom_fields: A dictionary with fields that should be added to the entry.
                              These fields will overwrite any of the standard optimade fields that are generated by this module.
                              This can be useful when an OPTIMADE field, such as nperiodic_dimensions dimension_types, can not be generated from the trajectory file.
    """

    # step 1: load file(s) with trajectory data
    # TODO It is probably better to use paths from the Path library instead of strings for the filenames
    # TODO Determine whether the file is small enough to store in memory in that case set "in_memory=True"
    if trajectory_files:
        traj = mda.Universe(structure_file, [str(file) for file in trajectory_files])
    else:
        traj = mda.Universe(structure_file, format=file_format)

    # Step2 generate pymatgen structure from MDAnalysis structure, so we can also use the methods of pymatgen.
    if not last_frame:
        last_frame = len(traj.trajectory)
    if not reference_frames:
        reference_frames = [last_frame - 1]
    elif isinstance(reference_frames, list):
        reference_frames = [reference_frames]
    try:
        struct = generate_pymatgen_from_mdanal(traj, reference_frames[-1])
    except:
        struct = None
    # step 3: generate all the neccesary OPTIMADE fields from the data
    # TODO add automatically reading the units from the data if present

    n_frames = 1 + (((last_frame - 1) - first_frame) // frame_step)

    # TODO it would be nice to also allow adding structures in the same way we add trajectories
    # type
    entry_type = "trajectories"

    # immutable_id (OPTIONAL)
    # last_modified handled by the function current_time()
    if struct:
        # elements
        elements = sorted(struct.symbol_set)
        # nelements
        nelements = len(elements)
        # elements_ratios
        elements_ratios = [
            float(i)
            for i in re.sub(
                "[A-Z][a-z]*",
                "",
                struct.composition.fractional_composition.alphabetical_formula,
            ).split()
        ]
        # chemical_formula_descriptive
        chemical_formula_descriptive = struct.composition.alphabetical_formula.replace(
            " ", ""
        )
        # chemical_formula_reduced and chemical_formula_anonymous
        chemical_formula_reduced, chemical_formula_anonymous = get_formula_reduced_and_anonymous(struct)
    else:
        elements = None
        nelements = None
        elements_ratios = None
        chemical_formula_descriptive = None
        chemical_formula_reduced, chemical_formula_anonymous = None, None


    # chemical_formula_hill(OPTIONAL) Not yet implemented

    # dimension_types
    dimension_types = None  # TODO: The files I use for testing do not explicitly store this information. Most likely it is periodic but to be sure I should probably check whether: 1. particles move through the periodic boundaries 2. There are chemical bonds that go through the periodic boundary 3. particles that are outside the unitcell

    # nperiodic_dimensions # todo: check whether dimension_types is in user supplied fields so we can generate nperiodic_dimensions from it.
    if dimension_types:
        nperiodic_dimensions = sum(dimension_types)
    else:
        nperiodic_dimensions = None

    # lattice_vectors
    latt = get_lattice_dict(traj, reference_frames[-1])
    if latt is None:
        lattice_vectors = None
    else:
        lattice_vectors = pymatgen.core.Lattice.from_dict(latt).matrix.tolist()

    # cartesian_site_positions
    # cartesian_site_positions = traj.trajectory[reference_frames[-1]].positions.tolist()  # No longer neccesary if we no longer have real reference frames.

    # nsites
    nsites = traj.atoms.n_atoms

    # species_at_sites
    if hasattr(traj.atoms, "names"):
        species_at_sites = traj.atoms.names.tolist()
    else:
        species_at_sites = ["X"]*nsites

    # species  # TODO the atom names/labels may not be unique enough in some cases. In that case extra descriptors such as the number of attached hydrogens or the charge have to be added.
    species = []
    for specie in set(species_at_sites):
        index = species_at_sites.index(specie)
        specie_dict = {
                "name": specie,
                "concentration": [getoccu(traj, index)],
            }
        if hasattr(traj.atoms, "elements"):
            specie_dict["chemical_symbols"] = [traj.atoms.elements[index]]
            specie_dict["mass"]: [traj.atoms.masses[index]]
        else:
            specie_dict["chemical_symbols"] = ["X"]

        if hasattr(traj.residues, "icodes"):
            specie_dict["_biomol_atom_name"] = specie # this will only become relevant when a more advanced species name generation is implemented.

        species.append(specie_dict)

    # assemblies(OPTIONAL)

    # structure_features
    # TODO make more checks to see which properties should be set here.
    structure_features = []
    for specie in species:
        if len(specie["chemical_symbols"]) > 1:
            structure_features.append("disorder")
            break

    # MDAnalysis throws a warning when the timestep is not specified but does return a reasonable value of 1.0 ps. This can be confusing, so I therefore choose to catch this warning.
    # We do not want this warning to be displayed to the user, so we temporarily allow only errors to be reported.
    warnings.filterwarnings("error")
    try:
        dt = traj.trajectory[0].dt * frame_step
        time_present = True
    except UserWarning:
        time_present = False
    warnings.filterwarnings("default")

    reference_frames = [1+((frame-first_frame)//frame_step) for frame in reference_frames]
    # reference_frame_opt = 1 + (reference_frames - first_frame) / frame_step # +1 because optimade starts counting from 1 while python starts from 0
    # reference_frame_opt_int = int(reference_frame_opt)
    # if reference_frame_opt != reference_frame_opt_int:
    #     reference_frame_opt_int = None

    entry = {
        "elements": elements,
        "nelements": nelements,
        "elements_ratios": elements_ratios,
        "chemical_formula_descriptive": chemical_formula_descriptive,
        "chemical_formula_reduced": chemical_formula_reduced,
        "chemical_formula_anonymous": chemical_formula_anonymous,
        "dimension_types": dimension_types,
        "nperiodic_dimensions": nperiodic_dimensions,
        "lattice_vectors": lattice_vectors,
        "cartesian_site_positions": None,
        "nsites": nsites,
        "species_at_sites": species_at_sites,
        "species": species,
        "structure_features": structure_features,
        "nframes": n_frames,
        "reference_frames": reference_frames,
        "type": entry_type,
        "last_modified": last_modified(),
    }

    if time_present:  # if the time step is not zero or none
        entry["time_step"] = dt
        entry["time_0"] = traj.trajectory[0].time

    # step 3.5 add references
    if references:
        entry["relationships"] = generate_relationships(references)

    # Generate biomolecular fields:

    # TODO need a more thorough way to determine if it is a biomolecular simulation.
    # if hasattr(traj.residues, "icodes"):
    #     sequences, residues, chains = get_biomol_fields(traj)
    #     nested_dict_update(entry, gen_traj_prop("sequences", "constant", values=[sequences]))
    #     nested_dict_update(entry, gen_traj_prop("residues", "constant", values=[residues]))
    #     nested_dict_update(entry, gen_traj_prop("chains", "constant", values=[chains]))

    # Add custom database fields.
    entry = {**entry, **custom_fields}

    # Step 4: store trajectory data

    trajectories_coll = create_collection(  # Todo Check whether this part cannot be imported with "from optimade.server.routers.trajectories import trajectories_coll"
        name=CONFIG.trajectories_collection,
        resource_cls=TrajectoryResource,
        resource_mapper=TrajectoryMapper,
    )
    if traj_id:
        if trajectories_coll.findOne({"id": traj_id}):
            raise ValueError(f"The id {traj_id} is already in the data base. No two entries can have the same id value.")

    trajectories_coll.insert([entry])
    # todo: add more try except clauses below so we cannot end up with an incomplete entry in the database
    if not traj_id:
        traj_id = entry["_id"]
    fields_to_add = {"id": str(traj_id)}

    # Write trajectory data to gridfs file system
    # If the trajectory is larger than about 32 kb store it in gridfs
    try:
        if n_frames * nsites * 3 * 8 > 32 * 1024:
            property_name = "cartesian_site_positions"
            # TODO Test this error handling.
            # TODO check whether there are more properties that can be stored such as force and velocities
            frames_to_be_stored = slice(first_frame, last_frame, frame_step)
            arr = np.array([np.array(frame.positions) for frame in traj.trajectory[frames_to_be_stored]])
            slice_object = [{"start": first_frame+1, "stop": last_frame, "step": frame_step}] + [{"start": 1, "stop": arr.shape[i], "step": 1} for i in range(1, len(arr.shape))]
            from optimade.server.routers.partial_data import partial_data_coll
            filename = str(traj_id) + ":" + property_name + ".npy"
            metadata = {"dtype": {"itemsize": arr.dtype.itemsize, "name": arr.dtype.name},   # todo perhaps it is good to create a class for the metadata of a file stroed in gridfs
                        "slice_obj": slice_object,
                        "endpoint": "trajectories",
                        "parent_id": traj_id,
                        "property_name": property_name,
                        "dim_names": ["dim_frames", "dim_sites", "dim_cartesian_dimensions"],
                        }
            from tempfile import TemporaryFile
            output_file = TemporaryFile()
            np.save(output_file, arr)
            output_file.seek(0)
            partial_data_coll.insert(output_file, filename=filename, metadata=metadata)
            output_file.close()
            partialdatafield = {"meta": {"partial_data_links": {property_name: None}}}
            nested_dict_update(fields_to_add, partialdatafield)
        else:  # If the trajectory is small it can be stored locally
            positions = []
            # To cover all the different cases for testing I encode the information about the trajectory in a different ways here.
            for i in range(first_frame, last_frame, frame_step):
                positions.append(traj.trajectory[i].positions.tolist())
            fields_to_add["cartesian_site_positions"] = positions
        # Add per property meta data so client can use property_ranges query parameter

        range_meta = {"meta":
                          {"property_metadata":
                               {property_name:
                                    {"range":
                                         {"layout": "dense",
                                          "indexable_dim": ["dim_frames", "dim_sites", "dim_cartesian_dimensions"],
                                          "data_range": slice_object,
                                          "nvalues": math.ceil((last_frame-first_frame)/frame_step)*nsites*3
                                         }
                                     }
                                }
                           }
                      }

        nested_dict_update(fields_to_add, range_meta)
        trajectories_coll.collection.update_one({"_id": entry["_id"]}, {"$set": fields_to_add})
    except Exception as error:
        trajectories_coll.collection.delete_one({"_id": entry["_id"]})
        raise Exception(
            f"Unable to store trajectory data. Entry of the {structure_file} and {trajectory_files} into the Database has been aborted.\n" + str(error))


def nested_dict_update(dict1, dict2):
    for key, val in dict2.items():
        if key in dict1 and isinstance(val, dict):
            if isinstance(dict1[key], dict):
                nested_dict_update(dict1[key], dict2[key])
        else:
            dict1[key] = dict2[key]
    return dict1


def flip_chem_form_anon(chemical_formula_anonymous: str) -> str:
    """Converts an anonymous chemical formula with the most numerous element in the last position to an
    anonymous chemical formula with the most numerous element in the first position and vice versa."""
    numbers = list(re.split('[A-Z][a-z]*', chemical_formula_anonymous))
    anon_elem = list(re.findall('[A-Z][^A-Z]*', re.sub('[0-9]+', '', chemical_formula_anonymous)))

    return "".join(
        [
            y
            for x in range(len(anon_elem))
            for y in [anon_elem[x], numbers[len(anon_elem) - x]]
        ]
    )


def getoccu(traj, index):
    if hasattr(traj.atoms, "occupancies"):
        return traj.atoms.occupancies[index]
    return 1.0


def generate_relationships(references):
    references_coll = create_collection(
        name=CONFIG.references_collection,
        resource_cls=ReferenceResource,
        resource_mapper=ReferenceMapper,
    )
    list_references = []
    for reference in references:

        list_references.append({"type": "references", "id": reference["id"]})
        reference["last_modified"] = last_modified()
        ref_in_db = references_coll.collection.find_one({"id": reference["id"]})
        if not ref_in_db:
            references_coll.insert(
                [reference]
        )  # TODO check whether if it is already in the data base and if so the meta fields are the same.

    return {"references": {"data": list_references}}


def last_modified():
    return datetime.datetime.utcnow().replace(
        microsecond=0
    )  # MongeDB does not accept microseconds


def get_res_type(resname):
    if resname in AMINOACID_DICT:
        return "amino_acid"
    if resname in DNA_DICT:
        return "DNA"
    if resname in RNA_LIST:
        return "RNA"
    if resname in SOLVENTS:
        return "solvent"
    if resname in IONS:
        return "ion"
    return "other"


def get_chain_indixes(seg_id_set, chain_id_to_index):
    chains = []
    for chain_id in seg_id_set:
        if chain_id not in chain_id_to_index:
            chain_id_to_index[chain_id] = len(chain_id_to_index)
        chains.append(chain_id_to_index[chain_id])
    return chains, chain_id_to_index


def get_lattice_dict(traj, frame):

    if hasattr(traj.trajectory[frame], "dimensions") and traj.trajectory[frame].dimensions is not None:
        boxdim = traj.trajectory[frame].dimensions[:3]
        angles = traj.trajectory[frame].dimensions[3:]
    elif hasattr(traj, "dimensions") and traj.dimensions is not None:
        boxdim = traj.dimensions[:3]
        angles = traj.dimensions[3:]
    else:
        return None
    lattice = {
            "a": boxdim[0],
            "b": boxdim[1],
            "c": boxdim[2],
            "alpha": angles[0],
            "beta": angles[1],
            "gamma": angles[2],
        }
    return lattice


def generate_pymatgen_from_mdanal(traj, frame):
    """Generates a pymatgen structure object from a frame of a MDanalysis trajectory object.

    arguments: traj MDanalysis trajectory object.
               frame  the frame of the trajectory for which the pymatgen structure object should be generated.
    """
    if not hasattr(traj.atoms, "elements"): # If the trajectory is loaded without the topology file the elements may not be defined
        return None

    nsites = traj.atoms.n_atoms

    lattice_dict = {"lattice": get_lattice_dict(traj, frame)}
    if lattice_dict["lattice"] is None:
        boxdim = [1.0, 1.0, 1.0]  # TODO: ADD warning that information about the lattice is missing
        lattice_dict["lattice"] = {
                "a": boxdim[0],
                "b": boxdim[1],
                "c": boxdim[2],
                "alpha": 90.0,
                "beta": 90.0,
                "gamma": 90.0,
            }
    else:
        boxdim = traj.trajectory[frame].dimensions[:3]

    # lattice_dict["charge"] = TODO MDTRAJ does not read charges from pdb files yet so we cannot implement this yet.


    single_frame = len(traj.trajectory) == 1
    # Somehow reading a structure as a trajectory is very slow so instead we read the positions from the atoms.

    if (single_frame):
        if len(traj.trajectory) == 1:
            sites = [{"species": [{"element": traj.atoms.elements[i], "occu": getoccu(traj, i)}],
                "abc": traj.atoms.positions[i] / boxdim[:3]} for i in range(nsites)]
    else:
        sites = []
        for i in range(nsites):
            site = {
                "species": [
                    {"element": traj.atoms.elements[i], "occu": getoccu(traj, i)}
                ],
                "abc": traj.trajectory[frame].positions[i] / boxdim[:3],
            }
            sites.append(site)

    lattice_dict["sites"] = sites
    return pymatgen.core.structure.IStructure.from_dict(lattice_dict)


def get_formula_reduced_and_anonymous(struct):
    def sort_second(val):
        return val[1]

    # TODO find a better method for rounding down the elemental composition.
    formula = struct.composition.alphabetical_formula
    formula_components = re.split("([A-Z][a-z]?)", formula)
    formula_pairs = [(formula_components[i], round(float(formula_components[i + 1]))) for i in range(1, len(formula_components), 2)]
    gcd = np.gcd.reduce([i[1] for i in formula_pairs])
    formula_reduced = "".join(
        [
            "".join([pair[0], re.sub("^[1]$", "", str(pair[1]//gcd))])
            for pair in formula_pairs
        ]
    )
    formula_pairs.sort(key=sort_second, reverse=True)
    formula_anonymous = "".join(
        [
            "".join([ANONYMOUS_ELEMENTS[i], re.sub("^[1]$", "", str(pair[1]//gcd))])
            for i, pair in enumerate(formula_pairs)
        ]
    )

    return formula_reduced, formula_anonymous


def get_biomol_fields(traj):
    biomol_residues = []
    biomol_chains = []
    chain_id_to_index = {}
    for res in traj.residues:
        if res.icode == "":
            insertion_code = None
        else:
            insertion_code = res.icode
        residue_dict = {
            "name": res.resname,
            "number": int(res.resnum),
            "insertion_code": insertion_code,
            "sites": res.atoms.indices.tolist(),
        }
        biomol_residues.append(residue_dict)

        # MDanalysis does not have a datatype equivalent to the chain in a pdb file so we have to construct it based on the information in the residues and the segments
        chain_index, chain_id_to_index = get_chain_indixes(
            [res.segid], chain_id_to_index
        )
        res_type = get_res_type(res.resname)
        if chain_index[0] >= len(biomol_chains):  # a new chain has been found
            chain_dict = {
                "name": res.segid,
                "residues": [int(res.resindex)],
                "types": [res_type],
                "sequences": [],
                "sequence_types": [],
            }
            biomol_chains.append(chain_dict)
        else:  # case existing chain
            biomol_chains[chain_index[0]]["residues"].append(int(res.resindex))
            if res_type not in biomol_chains[chain_index[0]]["types"]:
                biomol_chains[chain_index[0]]["types"].append(res_type)

    # _biomol_sequences

    biomol_sequences = []

    for seg in traj.segments:
        residue_name_list = []
        residue_index_list = []
        seg_id_set = set()
        current_type = "other"
        for res in seg.residues:
            res_type = get_res_type(res.resname)
            if (current_type in MONOMER_TYPES) and res_type != current_type:
                # reached the end of a sequence so make a new sequence
                sequence = "".join(residue_name_list)
                chains, chain_id_to_index = get_chain_indixes(
                    seg_id_set, chain_id_to_index
                )
                biomol_sequences.append(
                    {
                        "sequence": sequence,
                        "type": current_type,
                        "chains": chains,
                        "residues": residue_index_list,
                    }
                )  # TODO In the specifictaion written by Dani https://github.com/Materials-Consortia/OPTIMADE/pull/400/files a se
                current_type = res_type
                residue_index_list = []
                residue_name_list = []
                seg_id_set = set()

            # No sequence is generated for segment types other than RNA, DNA and aminoacids
            if (res_type in MONOMER_TYPES):
                # sequence continues
                if res_type == "DNA":
                    resname = DNA_DICT[res.resname]
                elif res_type == "amino_acid":
                    resname = AMINOACID_DICT[res.resname]
                else:  # case RNA
                    resname = res.resname
                residue_index_list.append(int(res.resindex))
                residue_name_list.append(resname)
                seg_id_set.add(res.segid)
                current_type = res_type
        # finally at the end of the sequence store the final sequence
        if current_type in MONOMER_TYPES:
            sequence = "".join(residue_name_list)
            chains, chain_id_to_index = get_chain_indixes(seg_id_set, chain_id_to_index)
            biomol_sequences.append(
                {
                    "sequence": sequence,
                    "type": current_type,
                    "chains": chains,
                    "residues": residue_index_list,
                }
            )

    # Add sequence info to chain
    for sequence in biomol_sequences:
        for chain_index in sequence["chains"]:
            biomol_chains[chain_index]["sequences"].append(sequence["sequence"])
            biomol_chains[chain_index]["sequence_types"].append(sequence["type"])

    return biomol_sequences, biomol_residues, biomol_chains


SOLVENTS = ["HOH"]
IONS = ["CL", "MN"]
MONOMER_TYPES = ("RNA", "DNA", "amino_acid")
DNA_DICT = {"DA": "A", "DC": "C", "DG": "G", "DT": "T", "DI": "I"}
RNA_LIST = ["C", "G", "A", "U", "I"]
AMINOACID_DICT = {
    "ALA": "A",
    "ARG": "R",
    "ASN": "N",
    "ASP": "D",
    "ASX": "B",
    "CYS": "C",
    "GLU": "E",
    "GLN": "Q",
    "GLX": "Z",
    "GLY": "G",
    "HID": "H", # The HID and HIE are sometimes erroneously used to indicate the position at which the proton is bound to the imidazole ring. # TODO HID is also used for a particular cofactor. The code should therefore be improved to distinguish these cases or raise an error
    "HIE": "H",
    "HIS": "H",
    "ILE": "I",
    "LEU": "L",
    "LYS": "K",
    "MET": "M",
    "NAG": "X",
    "PHE": "F",
    "PRO": "P",
    "SER": "S",
    "THR": "T",
    "TRP": "W",
    "TYR": "Y",
    "VAL": "V",
    "SEC": "U",
    "PYL": "O",
    "XLE": "J",
    "XAA": "X",
}
